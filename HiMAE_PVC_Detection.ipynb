{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd1f84d5",
   "metadata": {},
   "source": [
    "\n",
    "# HiMAE PVC Detection \n",
    "\n",
    "This notebook wires up the **HiMAE** backbone and a simple **linear probe** for PVC detection, using the code structure from the provided repo. It is designed to run end-to-end once you add your checkpoint paths and dataset files. \n",
    "\n",
    "Attached is a folder called `pvc/`which contains most of the source code to run the pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a144613f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T03:34:46.404270Z",
     "iopub.status.busy": "2025-11-25T03:34:46.403952Z",
     "iopub.status.idle": "2025-11-25T03:34:46.407020Z",
     "shell.execute_reply": "2025-11-25T03:34:46.406567Z",
     "shell.execute_reply.started": "2025-11-25T03:34:46.404247Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Optional: install dependencies if your environment doesn't have them\n",
    "# You can safely skip or adapt this cell.\n",
    "# %pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "# %pip install numpy pandas scikit-learn scipy matplotlib h5py pytorch-lightning tabulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98ef6390",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T03:34:46.408013Z",
     "iopub.status.busy": "2025-11-25T03:34:46.407795Z",
     "iopub.status.idle": "2025-11-25T03:34:46.412604Z",
     "shell.execute_reply": "2025-11-25T03:34:46.412146Z",
     "shell.execute_reply.started": "2025-11-25T03:34:46.407997Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os, sys, math, json, time, pathlib, warnings\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "# Optional metrics and utilities\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, accuracy_score, roc_curve\n",
    "from scipy.signal import resample as sp_resample\n",
    "\n",
    "import h5py\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5d485a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T03:34:46.413308Z",
     "iopub.status.busy": "2025-11-25T03:34:46.413107Z",
     "iopub.status.idle": "2025-11-25T03:34:46.418432Z",
     "shell.execute_reply": "2025-11-25T03:34:46.418003Z",
     "shell.execute_reply.started": "2025-11-25T03:34:46.413292Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo imported from: ./pvc\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Repo import path. Point this to the 'pvc' package root where utils/ and downstream_eval/ live.\n",
    "# If you're running next to this notebook, set it to a relative path.\n",
    "REPO_DIR = r\"./pvc\"  # change this to your local clone if needed\n",
    "\n",
    "if REPO_DIR not in sys.path:\n",
    "    sys.path.insert(0, REPO_DIR)\n",
    "\n",
    "# Imports from the repo\n",
    "from utils.model_arch.himae import HiMAE  # backbone\n",
    "# You can optionally use helpers if you like:\n",
    "# from downstream_eval.helpers import summarize_dataset\n",
    "print(\"Repo imported from:\", REPO_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6359501b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T03:34:46.419141Z",
     "iopub.status.busy": "2025-11-25T03:34:46.418921Z",
     "iopub.status.idle": "2025-11-25T03:34:46.423320Z",
     "shell.execute_reply": "2025-11-25T03:34:46.422908Z",
     "shell.execute_reply.started": "2025-11-25T03:34:46.419126Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Paths & configuration — EDIT THESE\n",
    "#\n",
    "# HDF5 is expected to contain datasets like: 'ppg' (or 'ecg'), 'labels', and optionally 'patient_ids'.\n",
    "# The PVC data in the repo's task_definition uses fs=25 Hz and 10-second windows (L = 250).\n",
    "#\n",
    "# If you have CSV metadata, set META_PATH as well; otherwise you can set it to None.\n",
    "\n",
    "H5_PATH   = \"./pvc_10s_synth.h5\"          # TODO: point to your local H5 file\n",
    "META_PATH = \"./pvc_10s_synth_metadata.csv\" # optional; set to None if not used\n",
    "SIGNAL_KEY = \"ppg\"                               # or \"ecg\" depending on your data\n",
    "LABEL_KEY  = \"labels\"                            # binary PVC label per segment\n",
    "PID_KEY    = \"patient_ids\"                       # optional; used for summaries/splits if present\n",
    "\n",
    "# HiMAE configuration. Adjust seg_len/sampling_freq to match your dataset.\n",
    "CFG = dict(\n",
    "    source=SIGNAL_KEY,          # 'ppg', 'ecg', or 'ppg+ecg'\n",
    "    sampling_freq=25,           # Hz\n",
    "    seg_len=10,                 # seconds\n",
    "    model_params=dict(\n",
    "        patch_len=50,           # must divide sampling_freq * seg_len; 25/50/125 are common here\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Checkpoint paths — provide one if you have a trained backbone and/or trained probe\n",
    "BACKBONE_CKPT = \"./himae_synth.ckpt\"   # can be a .pt/.pth/.ckpt; leave as None if not available\n",
    "LINEAR_PROBE_CKPT = None  # leave as None if you plan to train it here\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_WORKERS = 1\n",
    "VAL_SPLIT = 0.2   # random split fraction for validation if you don't have predefined splits\n",
    "SEED = 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97fd0ff4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T03:34:46.424551Z",
     "iopub.status.busy": "2025-11-25T03:34:46.424312Z",
     "iopub.status.idle": "2025-11-25T03:34:46.493340Z",
     "shell.execute_reply": "2025-11-25T03:34:46.492909Z",
     "shell.execute_reply.started": "2025-11-25T03:34:46.424535Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone weights loaded. Missing keys: 0 | Unexpected keys: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build the HiMAE backbone\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "backbone = HiMAE(CFG).to(device)\n",
    "backbone.eval()\n",
    "\n",
    "# Flexible checkpoint loader that works with plain state_dict or PL checkpoints\n",
    "def load_backbone_weights(model: nn.Module, ckpt_path: str):\n",
    "    if ckpt_path is None or not os.path.exists(ckpt_path):\n",
    "        print(\"No backbone checkpoint provided or path does not exist; skipping weight load.\")\n",
    "        return\n",
    "\n",
    "    state = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    # Handle common checkpoint formats\n",
    "    if isinstance(state, dict) and \"state_dict\" in state:\n",
    "        sd = state[\"state_dict\"]\n",
    "        # Strip possible prefixes like \"model.\", \"backbone.\", etc.\n",
    "        new_sd = {}\n",
    "        for k, v in sd.items():\n",
    "            nk = k\n",
    "            for pref in [\"model.\", \"backbone.\", \"net.\", \"module.\"]:\n",
    "                if nk.startswith(pref):\n",
    "                    nk = nk[len(pref):]\n",
    "            new_sd[nk] = v\n",
    "        missing, unexpected = model.load_state_dict(new_sd, strict=False)\n",
    "    elif isinstance(state, dict):\n",
    "        missing, unexpected = model.load_state_dict(state, strict=False)\n",
    "    else:\n",
    "        raise ValueError(\"Unrecognized checkpoint format\")\n",
    "\n",
    "    print(\"Backbone weights loaded. Missing keys:\", len(missing), \"| Unexpected keys:\", len(unexpected))\n",
    "\n",
    "load_backbone_weights(backbone, BACKBONE_CKPT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2064ee57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T03:34:46.494206Z",
     "iopub.status.busy": "2025-11-25T03:34:46.493961Z",
     "iopub.status.idle": "2025-11-25T03:34:46.501114Z",
     "shell.execute_reply": "2025-11-25T03:34:46.500701Z",
     "shell.execute_reply.started": "2025-11-25T03:34:46.494189Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Dataset for PVC segments stored in HDF5\n",
    "class PVCH5Dataset(Dataset):\n",
    "    def __init__(self, h5_path, signal_key=\"ppg\", label_key=\"labels\", pid_key=None,\n",
    "                 target_fs=25, seg_len=10, source=\"ppg\"):\n",
    "        self.h5_path = h5_path\n",
    "        self.signal_key = signal_key\n",
    "        self.label_key = label_key\n",
    "        self.pid_key = pid_key\n",
    "        self.target_fs = target_fs\n",
    "        self.seg_len = seg_len\n",
    "        self.source = source\n",
    "\n",
    "        if not os.path.exists(h5_path):\n",
    "            raise FileNotFoundError(f\"H5 not found at {h5_path}\")\n",
    "\n",
    "        self.h5 = h5py.File(h5_path, \"r\")\n",
    "        self.signals = self.h5[self.signal_key][...]   # shape (N, L) or (N, 1, L)\n",
    "        self.labels  = self.h5[self.label_key][...].astype(np.int64).reshape(-1)\n",
    "\n",
    "        if self.pid_key is not None and self.pid_key in self.h5:\n",
    "            self.pids = self.h5[self.pid_key][...]\n",
    "        else:\n",
    "            self.pids = np.arange(len(self.labels))\n",
    "\n",
    "        # Normalize signals to (N, L)\n",
    "        if self.signals.ndim == 3 and self.signals.shape[1] == 1:\n",
    "            self.signals = self.signals[:, 0, :]\n",
    "        elif self.signals.ndim != 2:\n",
    "            raise ValueError(f\"Expected signals of shape (N, L) or (N,1,L); got {self.signals.shape}\")\n",
    "\n",
    "        self.L = self.signals.shape[1]\n",
    "        self.expected_L = int(self.target_fs * self.seg_len)\n",
    "        print(f\"Loaded H5 with {len(self)} segments. Input length={self.L}, expected={self.expected_L}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "\n",
    "    def _ensure_length(self, x):\n",
    "        if x.shape[-1] == self.expected_L:\n",
    "            return x\n",
    "        # Simple resample if lengths mismatch\n",
    "        x_res = sp_resample(x, self.expected_L)\n",
    "        return x_res\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.signals[idx].astype(np.float32)\n",
    "        y = int(self.labels[idx])\n",
    "        pid = self.pids[idx]\n",
    "        x = self._ensure_length(x)\n",
    "        # HiMAE expects (B, 1, L). We'll add channel dimension in collate\n",
    "        return x, y, pid\n",
    "\n",
    "    def close(self):\n",
    "        try:\n",
    "            self.h5.close()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "def collate_batch(batch):\n",
    "    xs, ys, pids = zip(*batch)\n",
    "    xs = torch.from_numpy(np.stack(xs, axis=0)).float().unsqueeze(1)  # (B,1,L)\n",
    "    ys = torch.tensor(ys).long()\n",
    "    return xs, ys, pids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd0c4934",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T03:34:46.501802Z",
     "iopub.status.busy": "2025-11-25T03:34:46.501609Z",
     "iopub.status.idle": "2025-11-25T03:34:46.507216Z",
     "shell.execute_reply": "2025-11-25T03:34:46.506794Z",
     "shell.execute_reply.started": "2025-11-25T03:34:46.501788Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Feature extraction from the HiMAE encoder (bottleneck representation)\n",
    "@torch.no_grad()\n",
    "def encode_bottleneck(backbone: nn.Module, x: torch.Tensor) -> torch.Tensor:\n",
    "    # x: (B,1,L) float tensor\n",
    "    # returns: (B, C, Tprime) where C is final encoder channels (256 in default config)\n",
    "    backbone.eval()\n",
    "    current_x = x\n",
    "    for enc in backbone.encoder_layers:\n",
    "        current_x = enc(current_x)\n",
    "    return current_x  # bottleneck feature map\n",
    "\n",
    "class LinearProbe(nn.Module):\n",
    "    def __init__(self, in_dim=256, num_classes=1):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(in_dim, num_classes)\n",
    "\n",
    "    def forward(self, feats: torch.Tensor):\n",
    "        # feats: (B, C, T') -> global average pooling over time, then FC\n",
    "        pooled = feats.mean(dim=-1)\n",
    "        logits = self.fc(pooled).squeeze(-1)  # (B,)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "969da4e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T03:34:46.507893Z",
     "iopub.status.busy": "2025-11-25T03:34:46.507685Z",
     "iopub.status.idle": "2025-11-25T03:34:46.513199Z",
     "shell.execute_reply": "2025-11-25T03:34:46.512789Z",
     "shell.execute_reply.started": "2025-11-25T03:34:46.507878Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Data module-ish helpers\n",
    "def make_loaders(h5_path, cfg, batch_size=128, num_workers=4, val_split=0.2, signal_key=\"ppg\"):\n",
    "    ds = PVCH5Dataset(\n",
    "        h5_path=h5_path,\n",
    "        signal_key=signal_key,\n",
    "        label_key=LABEL_KEY,\n",
    "        pid_key=PID_KEY,\n",
    "        target_fs=cfg[\"sampling_freq\"],\n",
    "        seg_len=cfg[\"seg_len\"],\n",
    "        source=cfg[\"source\"],\n",
    "    )\n",
    "    N = len(ds)\n",
    "    n_val = int(round(val_split * N))\n",
    "    n_train = N - n_val\n",
    "    g = torch.Generator().manual_seed(SEED)\n",
    "    train_ds, val_ds = random_split(ds, [n_train, n_val], generator=g)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,\n",
    "                              num_workers=num_workers, pin_memory=True, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False,\n",
    "                            num_workers=num_workers, pin_memory=True, collate_fn=collate_batch)\n",
    "    return ds, train_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a22dc15a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T03:34:46.513947Z",
     "iopub.status.busy": "2025-11-25T03:34:46.513737Z",
     "iopub.status.idle": "2025-11-25T03:34:46.519973Z",
     "shell.execute_reply": "2025-11-25T03:34:46.519579Z",
     "shell.execute_reply.started": "2025-11-25T03:34:46.513915Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Training loop for the linear probe only (backbone frozen)\n",
    "def train_linear_probe(backbone, probe, train_loader, val_loader, epochs=10, lr=1e-3, weight_decay=1e-4):\n",
    "    backbone.eval()\n",
    "    for p in backbone.parameters():\n",
    "        p.requires_grad_(False)\n",
    "\n",
    "    probe = probe.to(device)\n",
    "    optim = torch.optim.AdamW(probe.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    best_val_auc = -np.inf\n",
    "    best_state = None\n",
    "\n",
    "    for ep in range(1, epochs+1):\n",
    "        probe.train()\n",
    "        running_loss = 0.0\n",
    "        for xb, yb, _ in train_loader:\n",
    "            xb = xb.to(device, non_blocking=True)\n",
    "            yb = yb.to(device, non_blocking=True).float()\n",
    "            feats = encode_bottleneck(backbone, xb)\n",
    "            logits = probe(feats)\n",
    "            loss = torch.nn.functional.binary_cross_entropy_with_logits(logits, yb)\n",
    "            optim.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            running_loss += loss.item() * xb.size(0)\n",
    "\n",
    "        # Validation\n",
    "        probe.eval()\n",
    "        y_true, y_score = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb, _ in val_loader:\n",
    "                xb = xb.to(device, non_blocking=True)\n",
    "                yb = yb.to(device, non_blocking=True).float()\n",
    "                feats = encode_bottleneck(backbone, xb)\n",
    "                logits = probe(feats)\n",
    "                y_true.append(yb.cpu().numpy())\n",
    "                y_score.append(torch.sigmoid(logits).cpu().numpy())\n",
    "        y_true = np.concatenate(y_true)\n",
    "        y_score = np.concatenate(y_score)\n",
    "        try:\n",
    "            val_auc = roc_auc_score(y_true, y_score)\n",
    "            val_ap  = average_precision_score(y_true, y_score)\n",
    "        except ValueError:\n",
    "            val_auc, val_ap = float(\"nan\"), float(\"nan\")\n",
    "\n",
    "        print(f\"Epoch {ep:02d} | train_loss={running_loss/len(train_loader.dataset):.4f} | \"\n",
    "              f\"val_auc={val_auc:.4f} | val_ap={val_ap:.4f}\")\n",
    "\n",
    "        if val_auc > best_val_auc:\n",
    "            best_val_auc = val_auc\n",
    "            best_state = {k: v.cpu() for k, v in probe.state_dict().items()}\n",
    "\n",
    "    if best_state is not None:\n",
    "        probe.load_state_dict(best_state)\n",
    "    return probe, best_val_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d517ce3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T03:34:46.520666Z",
     "iopub.status.busy": "2025-11-25T03:34:46.520467Z",
     "iopub.status.idle": "2025-11-25T03:35:02.736686Z",
     "shell.execute_reply": "2025-11-25T03:35:02.736115Z",
     "shell.execute_reply.started": "2025-11-25T03:34:46.520651Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded H5 with 55861 segments. Input length=250, expected=250\n",
      "Epoch 01 | train_loss=183.0066 | val_auc=0.5735 | val_ap=0.0695\n",
      "Epoch 02 | train_loss=41.4369 | val_auc=0.5714 | val_ap=0.0731\n",
      "Epoch 03 | train_loss=41.6830 | val_auc=0.6352 | val_ap=0.1178\n",
      "Epoch 04 | train_loss=33.4461 | val_auc=0.6954 | val_ap=0.1136\n",
      "Epoch 05 | train_loss=37.2827 | val_auc=0.6582 | val_ap=0.1210\n",
      "Epoch 06 | train_loss=39.2719 | val_auc=0.6746 | val_ap=0.1049\n",
      "Epoch 07 | train_loss=31.3521 | val_auc=0.5214 | val_ap=0.0603\n",
      "Epoch 08 | train_loss=62.3732 | val_auc=0.7663 | val_ap=0.1162\n",
      "Epoch 09 | train_loss=31.3644 | val_auc=0.6081 | val_ap=0.1217\n",
      "Epoch 10 | train_loss=25.5817 | val_auc=0.5083 | val_ap=0.0506\n",
      "Best val AUC: 0.7662564648241595\n",
      "Saved probe to pvc_linear_probe.pt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# End-to-end wiring (disabled by default). Uncomment to run after editing paths.\n",
    "ds, train_loader, val_loader = make_loaders(H5_PATH, CFG, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS,\n",
    "                                            val_split=VAL_SPLIT, signal_key=SIGNAL_KEY)\n",
    "probe = LinearProbe(in_dim=256, num_classes=1)\n",
    "\n",
    "probe, best_val_auc = train_linear_probe(backbone, probe, train_loader, val_loader, epochs=10, lr=1e-3)\n",
    "print(\"Best val AUC:\", best_val_auc)\n",
    "torch.save(probe.state_dict(), \"pvc_linear_probe.pt\")\n",
    "print(\"Saved probe to pvc_linear_probe.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba91c660",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T03:35:02.737691Z",
     "iopub.status.busy": "2025-11-25T03:35:02.737418Z",
     "iopub.status.idle": "2025-11-25T03:35:02.741494Z",
     "shell.execute_reply": "2025-11-25T03:35:02.741099Z",
     "shell.execute_reply.started": "2025-11-25T03:35:02.737670Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Inference helper to get PVC probabilities for a dataloader\n",
    "@torch.no_grad()\n",
    "def infer_pvc_probs(backbone, probe, loader):\n",
    "    backbone.eval()\n",
    "    probe.eval()\n",
    "    all_pids, all_probs, all_labels = [], [], []\n",
    "    for xb, yb, pids in loader:\n",
    "        xb = xb.to(device, non_blocking=True)\n",
    "        feats = encode_bottleneck(backbone, xb)\n",
    "        logits = probe(feats)\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "        all_probs.append(probs)\n",
    "        all_labels.append(np.asarray(yb))\n",
    "        all_pids.extend(list(pids))\n",
    "    return np.concatenate(all_probs), np.concatenate(all_labels), np.asarray(all_pids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b92a995",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T03:35:02.742244Z",
     "iopub.status.busy": "2025-11-25T03:35:02.742040Z",
     "iopub.status.idle": "2025-11-25T03:35:03.033344Z",
     "shell.execute_reply": "2025-11-25T03:35:03.032825Z",
     "shell.execute_reply.started": "2025-11-25T03:35:02.742228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC: 0.7662564648241595 AP: 0.11621493155214786\n",
      "Wrote pvc_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example: compute metrics and export predictions (disabled by default)\n",
    "test_loader = val_loader  \n",
    "probs, labels, pids = infer_pvc_probs(backbone, probe, test_loader)\n",
    "auc = roc_auc_score(labels, probs)\n",
    "ap  = average_precision_score(labels, probs)\n",
    "print(\"Test AUC:\", auc, \"AP:\", ap)\n",
    "df = pd.DataFrame({\"patient_id\": pids, \"label\": labels, \"p_pvc\": probs})\n",
    "df.to_csv(\"pvc_predictions.csv\", index=False)\n",
    "print(\"Wrote pvc_predictions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d9f7ac-44ed-4d3b-8041-74613bd04400",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
